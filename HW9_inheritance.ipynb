{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c6be6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26f31d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdea8b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6508c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y = np.loadtxt('non_linearly_separable.txt', skiprows=1, unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf41de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(Y):\n",
    "    n_labels = Y.shape[0]\n",
    "    result = np.zeros((n_labels, 2))\n",
    "    for i in range(n_labels):\n",
    "        result[i][Y[i]] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c596a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.column_stack((x1, x2))\n",
    "\n",
    "X_train = torch.from_numpy(x.astype(np.float32))\n",
    "\n",
    "Y_train_unencoded = y.astype(int).reshape(-1, 1)\n",
    "Y_train_ohe = one_hot_encode(Y_train_unencoded)\n",
    "Y_train = torch.from_numpy(Y_train_ohe.astype(np.float32)).view(-1,2)\n",
    "\n",
    "X_test = torch.from_numpy(x.astype(np.float32))\n",
    "Y_test = torch.from_numpy(y.astype(np.float32)).view(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0448459",
   "metadata": {},
   "source": [
    "![title](img/picture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d499fa5",
   "metadata": {},
   "source": [
    "## Neural Network 9-1 (BCELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d35ef4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnehiddenNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(OnehiddenNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.linear2(out)\n",
    "        y_pred = self.softmax(out) \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "01d84227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model 的設定、initial model的參數、建立model\n",
    "n_iters = 800\n",
    "learning_rate = 0.1\n",
    "n_hidden_nodes=10\n",
    "criterion = nn.BCELoss()\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = n_hidden_nodes\n",
    "num_classes= Y_train.shape[1]\n",
    "\n",
    "model = OnehiddenNN(input_size, hidden_size ,num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d37938d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9_/gr09sxx135g1s84jn44jfld80000gn/T/ipykernel_91649/3001672713.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50, Loss = 0.5638\n",
      "Iteration: 100, Loss = 0.4571\n",
      "Iteration: 150, Loss = 0.2382\n",
      "Iteration: 200, Loss = 0.1921\n",
      "Iteration: 250, Loss = 0.1591\n",
      "Iteration: 300, Loss = 0.1354\n",
      "Iteration: 350, Loss = 0.1182\n",
      "Iteration: 400, Loss = 0.1023\n",
      "Iteration: 450, Loss = 0.0902\n",
      "Iteration: 500, Loss = 0.0807\n",
      "Iteration: 550, Loss = 0.0728\n",
      "Iteration: 600, Loss = 0.0661\n",
      "Iteration: 650, Loss = 0.0603\n",
      "Iteration: 700, Loss = 0.0553\n",
      "Iteration: 750, Loss = 0.0510\n",
      "Iteration: 800, Loss = 0.0470\n"
     ]
    }
   ],
   "source": [
    "# for 迴圈跑數值\n",
    "for iters in range(n_iters):\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (iters+1) % 50 == 0:\n",
    "        print(f'Iteration: {iters+1}, Loss = {loss.item():.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f776335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9_/gr09sxx135g1s84jn44jfld80000gn/T/ipykernel_91649/3001672713.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = self.softmax(out)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    _,y_predicted_cls = torch.max(y_predicted,1)\n",
    "    acc = (y_predicted_cls.eq(torch.squeeze(Y_test)).sum() / Y_test.shape[0] )*100\n",
    "    print(f'accuracy: {acc.item():.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be01ab4",
   "metadata": {},
   "source": [
    "## Neural Network 9-2 (CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f6df42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnehiddenNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(OnehiddenNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        y_pred = self.linear2(out)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b994bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 800\n",
    "learning_rate = 0.1\n",
    "n_hidden_nodes=10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = n_hidden_nodes\n",
    "num_classes= Y_train.shape[1]\n",
    "\n",
    "model = OnehiddenNN(input_size, hidden_size ,num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f43f2d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50, Loss = 0.5781\n",
      "Iteration: 100, Loss = 0.4735\n",
      "Iteration: 150, Loss = 0.2378\n",
      "Iteration: 200, Loss = 0.1965\n",
      "Iteration: 250, Loss = 0.1691\n",
      "Iteration: 300, Loss = 0.1521\n",
      "Iteration: 350, Loss = 0.1371\n",
      "Iteration: 400, Loss = 0.1146\n",
      "Iteration: 450, Loss = 0.0959\n",
      "Iteration: 500, Loss = 0.0859\n",
      "Iteration: 550, Loss = 0.0795\n",
      "Iteration: 600, Loss = 0.0746\n",
      "Iteration: 650, Loss = 0.0706\n",
      "Iteration: 700, Loss = 0.0672\n",
      "Iteration: 750, Loss = 0.0642\n",
      "Iteration: 800, Loss = 0.0602\n"
     ]
    }
   ],
   "source": [
    "for iters in range(n_iters):\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (iters+1) % 50 == 0:\n",
    "        print(f'Iteration: {iters+1}, Loss = {loss.item():.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7ca96b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.3333%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    _,y_predicted_cls = torch.max(y_predicted,1)\n",
    "    acc = (y_predicted_cls.eq(torch.squeeze(Y_test)).sum() / Y_test.shape[0] )*100\n",
    "    print(f'accuracy: {acc.item():.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d1385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
